---
title: "DIBmix Mixed-Type Clustering Analysis of PISA Educational Resilience"
author: "Your Name"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true
    toc_depth: 3
    toc_float: true
    number_sections: true
    theme: united
    highlight: tango
    code_folding: show
  pdf_document:
    toc: true
    number_sections: true
params:
  data_dir: "/Users/amarkos/PISA_Data/"
  target_countries: "GRC"
  disadvantaged_threshold: 0.25
  k_range_min: 2
  k_range_max: 8
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  warning = FALSE,
  message = FALSE,
  fig.width = 10,
  fig.height = 6,
  cache = TRUE,
  comment = NA
)

# Set global options
options(scipen = 999)
```

## Executive Summary

This analysis applies DIBmix mixed-type clustering to identify distinct resilience patterns among disadvantaged students in the PISA (Programme for International Student Assessment) dataset. The study focuses on Greece across multiple PISA cycles, using advanced clustering validation techniques to discover educational resilience typologies.

Key Features:

- Native handling of mixed continuous + categorical variables
- Robust cluster validation using composite indices
- Cross-cycle stability analysis
- Comprehensive educational interpretation

## Library Setup and Configuration

```{r}
# ---- Core Libraries for DIBmix Analysis ----
library(haven)       # SPSS file reading
library(data.table)  # High-performance data operations
library(dtplyr)      # dplyr syntax with data.table backend
library(labelled)    # Handle SPSS labels
library(psych)       # Descriptive statistics
library(ggplot2)     # Visualizations
library(tidyr)       # Data reshaping
library(dplyr)       # Data manipulation
library(gridExtra)   # Plot arrangements
library(viridis)     # Color palettes
library(scales)      # Scaling functions
library(fpc)         # Clustering validation
library(mclust)      # Adjusted Rand Index
library(fastDummies) # Dummy variable creation
library(mice)        # Multiple imputation

# ---- DIBmix Package (Required) ----
if (!requireNamespace("IBclust", quietly = TRUE)) {
  stop("IBclust package required but not available. Install with: devtools::install_github('amarkos/IBclust')")
}
library(IBclust)

# ---- Configuration ----
setDTthreads(0) # Use all available cores
```

## ---- Analysis Parameters ----

```{r}
data_dir <- params$data_dir
target_countries <- params$target_countries
DISADVANTAGED_THRESHOLD <- params$disadvantaged_threshold
K_RANGE <- params$k_range_min:params$k_range_max

# Validate data directory
if (!dir.exists(data_dir)) {
  stop("Data directory does not exist: ", data_dir)
}

path <- function(fname) file.path(data_dir, fname)

cat("Analysis Configuration:\n")
cat("- Data directory:", data_dir, "\n")
cat("- Target countries:", target_countries, "\n")
cat("- Disadvantaged threshold:", DISADVANTAGED_THRESHOLD, "\n")
cat("- K range:", paste(K_RANGE, collapse = "-"), "\n")
```

## DIBmix Clustering Infrastructure

### Custom DIBmix Function for Mixed-Type Data

```{r}
# ---- Enhanced DIBmix CBI Function ----
dibmixCBI <- function(data, ncl=NULL, k=NULL, catcols=NULL, contcols=NULL, 
                      lambda=-1, nstart=1, ...){
  
  # Handle parameter compatibility
  if (!is.null(k)) ncl <- k
  if (is.null(ncl)) stop("Number of clusters (ncl or k) must be specified")
  
  # Ensure data is a data frame (DIBmix requires this)
  data <- as.data.frame(data)
  
  # Handle column specification more robustly
  if (is.null(catcols) && is.null(contcols)) {
    # Auto-detect column types
    catcols <- which(sapply(data, function(x) {
      is.integer(x) && length(unique(x)) <= 10
    }))
    contcols <- which(sapply(data, function(x) {
      is.numeric(x) && length(unique(x)) > 10
    }))
  }
  
  # Ensure all data is numeric for preprocessing
  for (i in 1:ncol(data)) {
    if (!is.numeric(data[, i])) {
      data[, i] <- as.numeric(data[, i])
    }
  }
  
  # CRITICAL FIX: DIBmix requires non-empty catcols and contcols vectors
  if (length(catcols) == 0) {
    # Create a dummy categorical variable by discretizing one continuous variable
    if (length(contcols) > 1) {
      var_to_discretize <- contcols[which.min(sapply(contcols, function(i) var(data[, i], na.rm = TRUE)))]
      
      # Create categorical version by cutting into quantiles
      dummy_cat_col <- ncol(data) + 1
      data[, dummy_cat_col] <- as.integer(cut(data[, var_to_discretize], 
                                              breaks = quantile(data[, var_to_discretize], 
                                                                probs = c(0, 0.33, 0.67, 1), na.rm = TRUE),
                                              include.lowest = TRUE))
      
      # Update column indices
      catcols <- dummy_cat_col
      contcols <- setdiff(contcols, var_to_discretize)
      
      cat("DIBmix: Created dummy categorical variable from continuous data\n")
    } else {
      stop("DIBmix requires at least one categorical and one continuous variable")
    }
  }
  
  # Ensure we have at least one continuous column
  if (length(contcols) == 0) {
    stop("DIBmix requires at least one continuous variable")
  }
  
  # Validate that catcols and contcols don't overlap
  if (any(catcols %in% contcols)) {
    stop("catcols and contcols cannot overlap")
  }
  
  cat("DIBmix: Using", length(contcols), "continuous and", length(catcols), "categorical columns\n")
  
  tryCatch({
    # Apply DIBmix clustering with proper parameters
    c1 <- IBclust::DIBmix(X = data, ncl = ncl, catcols = catcols, 
                          contcols = contcols, lambda = lambda, 
                          nstart = nstart, ...)
    
    # Extract partition from the clustering result
    partition <- c1$Cluster
    
    # Create cluster list (indices for each cluster)
    cl <- list()
    nc <- ncl
    
    for (i in 1:nc) {
      cl[[i]] <- which(partition == i)
    }
    
    # Return standardized CBI output
    out <- list(
      result = c1,
      nc = nc,
      nccl = nc,
      clusterlist = cl,
      partition = partition,
      clustermethod = "dibmix"
    )
    
    return(out)
    
  }, error = function(e) {
    cat("DIBmix failed with error:", e$message, "\n")
    stop("DIBmix clustering failed: ", e$message)
  })
}
```

## Statistics Extraction Functions

```{r}
# ---- Statistics Extraction from DIBmix Results ----
extract_dibmix_statistics_final <- function(cbs_result) {
  if (is.null(cbs_result$sstat)) {
    cat("No sstat component available\n")
    return(NULL)
  }
  
  sstat <- cbs_result$sstat
  
  if (length(sstat) > 0 && is.list(sstat[[1]])) {
    stats_container <- sstat[[1]]
    
    # Get method and k range info
    method_name <- if (!is.null(sstat$method)) sstat$method else "DIBmix"
    min_k <- sstat$minG
    max_k <- sstat$maxG
    k_values <- seq(min_k, max_k)
    
    cat("Extracting statistics for k =", paste(k_values, collapse = ", "), "\n")
    
    results_list <- list()
    
    for (i in seq_along(k_values)) {
      k_val <- k_values[i]
      stats_position <- i + 1  # Skip the first NA element
      
      if (stats_position <= length(stats_container)) {
        stats_for_k <- stats_container[[stats_position]]
        
        if (is.list(stats_for_k) && length(stats_for_k) > 0) {
          # Create row for this k value
          row_data <- data.frame(
            method = method_name,
            k = k_val,
            stringsAsFactors = FALSE
          )
          
          # Add all available statistics
          for (stat_name in names(stats_for_k)) {
            if (is.numeric(stats_for_k[[stat_name]]) && length(stats_for_k[[stat_name]]) == 1) {
              row_data[[stat_name]] <- stats_for_k[[stat_name]]
            }
          }
          
          results_list[[i]] <- row_data
          cat("Extracted statistics for k =", k_val, "with", length(names(stats_for_k)), "metrics\n")
        }
      }
    }
    
    # Combine all results
    if (length(results_list) > 0) {
      final_results <- do.call(rbind, results_list)
      cat("Successfully extracted", nrow(final_results), "rows of statistics\n")
      return(final_results)
    }
  }
  
  cat("Could not extract statistics from structure\n")
  return(NULL)
}

# ---- Master Statistics Extraction Function ----
extract_dibmix_statistics_master <- function(cbs_result) {
  # Try direct structure extraction
  result1 <- extract_dibmix_statistics_final(cbs_result)
  
  if (!is.null(result1)) {
    return(result1)
  }
  
  cat("All extraction methods failed\n")
  return(NULL)
}
```

## Composite Index Functions

```{r}
# ---- Composite Index Creation for Educational Resilience ----
create_resilience_weights_working <- function(available_stats, index_type = "resilience_types") {
  cat("Available statistics for weighting:\n")
  print(available_stats)
  
  n_stats <- length(available_stats)
  weights <- rep(0, n_stats)
  names(weights) <- available_stats
  
  if (index_type == "resilience_types") {
    # A1 Index: For interpretable resilience types
    if ("avewithin" %in% available_stats) weights["avewithin"] <- 1
    if ("entropy" %in% available_stats) weights["entropy"] <- 1
    if ("sindex" %in% available_stats) weights["sindex"] <- 1
    if ("pearsongamma" %in% available_stats) weights["pearsongamma"] <- 1
    if ("asw" %in% available_stats) weights["asw"] <- 0.8
    if ("minsep" %in% available_stats) weights["minsep"] <- 0.5
    
  } else if (index_type == "student_matching") {
    # A2 Index: For fine-grained student matching
    if ("entropy" %in% available_stats) weights["entropy"] <- 1.5
    if ("avewithin" %in% available_stats) weights["avewithin"] <- 1
    if ("asw" %in% available_stats) weights["asw"] <- 1
    if ("sindex" %in% available_stats) weights["sindex"] <- 0.8
  }
  
  # Only keep weights for statistics that actually exist and have non-zero weights
  final_weights <- weights[weights > 0 & names(weights) %in% available_stats]
  
  if (length(final_weights) == 0) {
    cat("Warning: No valid statistics found for composite index\n")
    
    # Fallback: use asw (silhouette width) if available
    if ("asw" %in% available_stats) {
      final_weights <- c("asw" = 1)
      cat("Using asw (silhouette width) as fallback\n")
    } else {
      return(NULL)
    }
  }
  
  # Display non-zero weights
  cat(paste("\nComposite index weights for", index_type, ":\n"))
  for (stat in names(final_weights)) {
    cat("  ", stat, ":", final_weights[stat], "\n")
  }
  
  return(final_weights)
}

calculate_composite_index_working <- function(results_df, weights) {
  if (is.null(results_df) || is.null(weights) || nrow(results_df) == 0) {
    return(NULL)
  }
  
  # Check that all weighted statistics are available
  missing_stats <- setdiff(names(weights), names(results_df))
  if (length(missing_stats) > 0) {
    cat("Missing statistics for composite index:", paste(missing_stats, collapse = ", "), "\n")
    weights <- weights[names(weights) %in% names(results_df)]
    if (length(weights) == 0) {
      return(NULL)
    }
  }
  
  # Calculate composite index for each row
  composite_scores <- numeric(nrow(results_df))
  
  for (i in 1:nrow(results_df)) {
    row_values <- numeric(length(weights))
    names(row_values) <- names(weights)
    
    for (stat_name in names(weights)) {
      if (stat_name %in% names(results_df)) {
        row_values[stat_name] <- results_df[i, stat_name]
      }
    }
    
    # Calculate weighted average
    composite_scores[i] <- weighted.mean(row_values, weights, na.rm = TRUE)
  }
  
  # Add composite index to results
  results_df$index <- composite_scores
  
  # Sort by composite index (higher is better)
  results_df <- results_df[order(results_df$index, decreasing = TRUE), ]
  
  return(results_df)
}
```

## Data Loading and Preprocessing

### PISA Data Configuration

```{r}
# ---- PISA Cycle Configuration ----
pisa_cycles <- list(
  "2015" = list(
    student_file = "CY6_MS_CMB_STU_QQQ.sav",
    school_file = "CY6_MS_CMB_SCH_QQQ.sav",
    year = 2015,
    var_mapping = list(
      student = c(
        "hisei" = "HISEI",
        "PARED" = "PAREDINT",
        "ANXTEST" = "ANXMAT",
        "MOTIVAT" = "MATHMOT"
      ),
      school = c(
        "STRATIO" = "STRATIO"
      )
    )
  ),
  "2018" = list(
    student_file = "CY07_MSU_STU_QQQ.sav",
    school_file = "CY07_MSU_SCH_QQQ.sav",
    year = 2018,
    var_mapping = list(
      student = c(),
      school = c(
        "STRATIO" = "STRATIO"
      )
    )
  ),
  "2022" = list(
    student_file = "CY08MSP_STU_QQQ.sav",
    school_file = "CY08MSP_SCH_QQQ.sav",
    year = 2022,
    var_mapping = list(
      student = c(),
      school = c(
        "SMRATIO" = "STRATIO"
      )
    )
  )
)

# Validate required files exist
all_files <- unlist(lapply(pisa_cycles, function(x) c(x$student_file, x$school_file)))
missing_files <- all_files[!file.exists(path(all_files))]
if (length(missing_files) > 0) {
  stop("Missing required files: ", paste(missing_files, collapse = ", "))
}

cat("PISA cycles configured:", names(pisa_cycles), "\n")
cat("All required files found ✓\n")
```

### Variable Definitions

```{r}
# ---- Core Variable Lists (Standardized Names) ----
core_student_vars <- list(
  ids = c("CNT", "CNTSCHID", "CNTSTUID"),
  achievement = c(
    paste0("PV", 1:10, "MATH"),
    paste0("PV", 1:10, "READ"),
    paste0("PV", 1:10, "SCIE")
  ),
  ses_background = c(
    "ESCS", "HISEI", "PAREDINT", "HOMEPOS", "ICTRES"
  ),
  demographics = c(
    "ST004D01T", "GRADE", "IMMIG", "REPEAT", "LANGN"
  ),
  motivation = c(
    "ANXMAT", "MATHMOT", "MATHEFF", "SCIEEFF", "JOYSCIE", "INTMAT",
    "GRWTHMND", "WORKMAST", "RESILIENCE", "MASTGOAL", "GFOFAIL", "COMPETE"
  ),
  behavior = c(
    "PERSEV", "TRUANCY", "HOMWRK", "DISCLIMA", "DIRINS", "PERFEED", "OUTHOURS"
  ),
  social_emotional = c(
    "BELONG", "TEACHSUP", "PEERREL", "BULLIED", "FAMSUP", "RELATST", 
    "EMOSUPS", "PERCOMP", "PERCOOP", "TEACHINT"
  ),
  resilience_other = c(
    "LIFESAT", "EUDMO", "WELLBEING", "ATTSCHL", "EXPDEG", "PHYSACT", "SCHWELL"
  ),
  weights = "W_FSTUWT"
)

core_school_vars <- list(
  ids = c("CNT", "CNTSCHID"),
  characteristics = c(
    "SCHSIZE", "SCHLTYPE", "STRATIO"
  ),
  resources = c(
    "STAFFSHORT", "EDUSHORT", "RATCMP1"
  ),
  weights = "W_SCHGRNRABWT"
)

cat("Variable categories defined:\n")
cat("- Student variables:", length(unlist(core_student_vars)), "\n")
cat("- School variables:", length(unlist(core_school_vars)), "\n")
```

### Data Loading Functions

```{r}
# ---- Enhanced File Reading with Variable Mapping ----
safe_read_pisa_with_mapping <- function(file_path, var_list, var_mapping,
                                        target_countries = NULL, cycle_year = NULL) {
  tryCatch({
    file_vars <- names(read_sav(file_path, n_max = 0))
    reverse_mapping <- setNames(names(var_mapping), var_mapping)
    vars_to_request <- sapply(var_list, function(std_var) {
      if (std_var %in% names(reverse_mapping)) {
        reverse_mapping[[std_var]]
      } else {
        std_var
      }
    })
    available_vars <- intersect(vars_to_request, file_vars)
    if (length(available_vars) == 0) {
      warning("No requested variables found in ", basename(file_path))
      return(NULL)
    }
    dt <- setDT(read_sav(file_path, col_select = any_of(available_vars)))
    for (old_name in names(var_mapping)) {
      new_name <- var_mapping[[old_name]]
      if (old_name %in% names(dt)) {
        setnames(dt, old_name, new_name)
      }
    }
    if (!is.null(target_countries) && "CNT" %in% names(dt)) {
      dt <- dt[CNT %in% target_countries]
    }
    if (!is.null(cycle_year)) {
      dt[, CYCLE := cycle_year]
    }
    std_names_loaded <- names(dt)[names(dt) %in% var_list]
    missing_vars <- setdiff(var_list, std_names_loaded)
    if (length(missing_vars) > 0) {
      cat("Cycle", cycle_year, "- Missing variables:",
          paste(missing_vars, collapse = ", "), "\n")
    }
    return(dt)
  }, error = function(e) {
    cat("Error reading file:", basename(file_path), "\n")
    cat("Error message:", e$message, "\n")
    return(NULL)
  })
}
```

### Load All PISA Cycles

```{r}
# ---- Load All PISA Cycles with Harmonization ----
cat("Loading PISA data for all cycles...\n")
all_student_vars <- unlist(core_student_vars, use.names = FALSE)
all_school_vars <- unlist(core_school_vars, use.names = FALSE)
pisa_student_list <- list()
pisa_school_list <- list()

for (cycle_name in names(pisa_cycles)) {
  cycle_info <- pisa_cycles[[cycle_name]]
  cat("\n--- Loading PISA", cycle_info$year, "---\n")
  
  stu_file <- path(cycle_info$student_file)
  stu_data <- safe_read_pisa_with_mapping(
    stu_file, all_student_vars, cycle_info$var_mapping$student,
    target_countries, cycle_info$year
  )
  if (!is.null(stu_data) && nrow(stu_data) > 0) {
    pisa_student_list[[cycle_name]] <- stu_data
    cat("Students loaded:", nrow(stu_data), "\n")
  }
  
  sch_file <- path(cycle_info$school_file)
  sch_data <- safe_read_pisa_with_mapping(
    sch_file, all_school_vars, cycle_info$var_mapping$school,
    target_countries, cycle_info$year
  )
  if (!is.null(sch_data) && nrow(sch_data) > 0) {
    pisa_school_list[[cycle_name]] <- sch_data
    cat("Schools loaded:", nrow(sch_data), "\n")
  }
}

# Harmonize variables across cycles
if (length(pisa_student_list) > 0) {
  all_student_vars_by_cycle <- lapply(pisa_student_list, names)
  common_student_vars <- Reduce(intersect, all_student_vars_by_cycle)
  cat("\nCommon student variables across cycles:", length(common_student_vars), "\n")
}
if (length(pisa_school_list) > 0) {
  all_school_vars_by_cycle <- lapply(pisa_school_list, names)
  common_school_vars <- Reduce(intersect, all_school_vars_by_cycle)
  cat("Common school variables across cycles:", length(common_school_vars), "\n")
}
```

## Data Processing and Resilience Definition

### PISA Cycle Processing Function

```{r}
# ---- Process PISA Cycle Function ----
process_pisa_cycle <- function(stu_dt, sch_dt, cycle_year) {
  if (is.null(stu_dt) || nrow(stu_dt) == 0) return(NULL)
  
  # FIXED: Compute average achievement scores with correct patterns
  stu_dt[, MATH_AVG := rowMeans(.SD, na.rm = TRUE), .SDcols = patterns("MATH$")]
  stu_dt[, READ_AVG := rowMeans(.SD, na.rm = TRUE), .SDcols = patterns("READ$")]
  stu_dt[, SCIE_AVG := rowMeans(.SD, na.rm = TRUE), .SDcols = patterns("SCIE$")]
  
  # Identify disadvantaged students (bottom quartile SES)
  escs_quartile <- quantile(stu_dt$ESCS, probs = DISADVANTAGED_THRESHOLD, na.rm = TRUE)
  stu_dt[, DISADVANTAGED := ifelse(ESCS <= escs_quartile, 1, 0)]
  
  # CORRECTED: Define resilience as Level 3+ in ALL three domains
  # Level 3 thresholds (consistent across PISA cycles)
  MATH_LEVEL3_THRESHOLD <- 482.38
  READ_LEVEL3_THRESHOLD <- 480.18
  SCIE_LEVEL3_THRESHOLD <- 484.14
  
  # Resilient = disadvantaged students achieving Level 3+ in ALL subjects
  stu_dt[DISADVANTAGED == 1, RESILIENT := ifelse(
    MATH_AVG >= MATH_LEVEL3_THRESHOLD & 
      READ_AVG >= READ_LEVEL3_THRESHOLD & 
      SCIE_AVG >= SCIE_LEVEL3_THRESHOLD, 1, 0)]
  
  # Filter to disadvantaged students
  disadv_dt <- stu_dt[DISADVANTAGED == 1]
  
  # Rest of your function remains the same...
  if (!is.null(sch_dt) && nrow(sch_dt) > 0) {
    disadv_dt <- merge(disadv_dt, sch_dt, by = c("CNT", "CNTSCHID", "CYCLE"), all.x = TRUE)
  }
  
  disadv_dt[is.na(RESILIENT), RESILIENT := 0]
  
  # Define clustering variables (ACHIEV_AVG removed)
  potential_clustering_vars <- c(
    "MATH_AVG", "READ_AVG", "SCIE_AVG",
    "ESCS", "HISEI", "PAREDINT", "HOMEPOS", "ICTRES",
    "ST004D01T", "GRADE", "IMMIG", "REPEAT", "LANGN", 
    "ANXMAT", "MATHMOT", "MATHEFF", "SCIEEFF", "JOYSCIE", "INTMAT",
    "GRWTHMND", "WORKMAST", "RESILIENCE", "MASTGOAL", "GFOFAIL", "COMPETE",
    "PERSEV", "TRUANCY", "HOMWRK", "DISCLIMA", "DIRINS", "PERFEED", "OUTHOURS",
    "BELONG", "TEACHSUP", "PEERREL", "BULLIED", "FAMSUP", "RELATST", 
    "EMOSUPS", "PERCOMP", "PERCOOP", "TEACHINT",
    "LIFESAT", "EUDMO", "WELLBEING", "ATTSCHL", "EXPDEG", "PHYSACT", "SCHWELL",
    "SCHSIZE", "SCHLTYPE", "STRATIO", "STAFFSHORT", "EDUSHORT", "RATCMP1"
  )
  
  clustering_vars <- intersect(potential_clustering_vars, names(disadv_dt))
  essential_vars <- c("W_FSTUWT", "RESILIENT", "CYCLE", "CNTSCHID", "CNTSTUID")
  final_vars <- c(clustering_vars, intersect(essential_vars, names(disadv_dt)))
  
  disadv_dt <- disadv_dt[, final_vars, with = FALSE]
  
  cat("Processed cycle", cycle_year, ": ", nrow(disadv_dt), "disadvantaged students with", 
      length(clustering_vars), "clustering variables\n")
  
  return(disadv_dt)
}
```

## Apply Processing to All Cycles

```{r}
# ---- Apply Processing to All Cycles ----
processed_list <- mapply(process_pisa_cycle, pisa_student_list, pisa_school_list, 
                         names(pisa_cycles), SIMPLIFY = FALSE)

# Display processing summary
cat("\n=== DATA PROCESSING SUMMARY ===\n")
total_students <- sum(sapply(processed_list, function(x) if (!is.null(x)) nrow(x) else 0))
successful_cycles <- sum(sapply(processed_list, function(x) !is.null(x)))

cat("- Total disadvantaged students:", total_students, "\n")
cat("- Successful processing cycles:", successful_cycles, "out of", length(pisa_cycles), "\n")

for (cycle in names(processed_list)) {
  if (!is.null(processed_list[[cycle]])) {
    n_students <- nrow(processed_list[[cycle]])
    n_resilient <- sum(processed_list[[cycle]]$RESILIENT, na.rm = TRUE)
    resilience_rate <- round(n_resilient / n_students * 100, 1)
    
    cat("- Cycle", cycle, ":", n_students, "students,", n_resilient, 
        "resilient (", resilience_rate, "%)\n")
  }
}
```

## Mixed-Type Data Preprocessing

### Advanced Preprocessing for DIBmix

```{r}
# ---- Advanced Preprocessing for Mixed-Type Data ----
preprocess_for_dibmix_clustering <- function(data) {
  clustering_vars <- colnames(data)
  
  # Remove SPSS labels and convert to appropriate types
  for (var in clustering_vars) {
    if (inherits(data[[var]], "haven_labelled")) {
      data[[var]] <- as.numeric(data[[var]])
    }
  }
  
  # Define variable types explicitly for DIBmix
  continuous_vars <- c("MATH_AVG", "READ_AVG", "SCIE_AVG", 
                       "ESCS", "HISEI", "PAREDINT", "HOMEPOS", "ICTRES", 
                       "GRADE", "SCHSIZE", "STRATIO", 
                       "ANXMAT", "MATHMOT", "MATHEFF", "SCIEEFF", "JOYSCIE", "INTMAT",
                       "GRWTHMND", "WORKMAST", "RESILIENCE", "MASTGOAL", "GFOFAIL", "COMPETE",
                       "PERSEV", "TRUANCY", "HOMWRK", "DISCLIMA", "DIRINS", "PERFEED", "OUTHOURS",
                       "BELONG", "TEACHSUP", "PEERREL", "BULLIED", "FAMSUP", "RELATST", 
                       "EMOSUPS", "PERCOMP", "PERCOOP", "TEACHINT",
                       "LIFESAT", "EUDMO", "WELLBEING", "ATTSCHL", "EXPDEG", "PHYSACT", "SCHWELL",
                       "STAFFSHORT", "EDUSHORT", "RATCMP1")
  
  nominal_vars <- c("ST004D01T", "IMMIG", "REPEAT", "LANGN", "SCHLTYPE")
  
  # Update variable lists based on what's actually available
  cont_available <- intersect(continuous_vars, clustering_vars)
  nom_available <- intersect(nominal_vars, clustering_vars)
  
  cat("Available continuous variables:", length(cont_available), "\n")
  cat("Available nominal variables:", length(nom_available), "\n")
  
  # Handle variables with >30% missing data - remove these first
  missing_pct <- sapply(clustering_vars, function(v) sum(is.na(data[[v]])) / nrow(data) * 100)
  vars_to_remove <- names(missing_pct)[missing_pct >= 30]
  vars_to_impute <- names(missing_pct)[missing_pct > 0 & missing_pct < 30]
  
  # Remove variables with excessive missing data
  if (length(vars_to_remove) > 0) {
    cat("Removing variables with >30% missing data:", paste(vars_to_remove, collapse = ", "), "\n")
    data <- data[, !names(data) %in% vars_to_remove, drop = FALSE]
    clustering_vars <- setdiff(clustering_vars, vars_to_remove)
    cont_available <- setdiff(cont_available, vars_to_remove)
    nom_available <- setdiff(nom_available, vars_to_remove)
    vars_to_impute <- setdiff(vars_to_impute, vars_to_remove)
  }
  
  # MICE imputation for variables with <30% missing values
  if (length(vars_to_impute) > 0) {
    total_missing <- sum(is.na(data[, vars_to_impute, drop = FALSE]))
    
    cat("Found", total_missing, "missing values across", length(vars_to_impute), "variables with <30% missing\n")
    cat("Variables to impute:", paste(vars_to_impute, collapse = ", "), "\n")
    
    # Prepare data for MICE imputation
    cat("Starting MICE imputation...\n")
    
    data_for_mice <- data
    categorical_vars_for_mice <- c()
    
    # Set up imputation methods for ALL variables (MICE requirement)
    imputation_methods <- rep("", ncol(data_for_mice))
    names(imputation_methods) <- names(data_for_mice)
    
    # Only set methods for variables that need imputation
    for (var in vars_to_impute) {
      if (var %in% cont_available) {
        data_for_mice[[var]] <- as.numeric(data_for_mice[[var]])
        imputation_methods[var] <- "pmm"  # Predictive mean matching for continuous
        cat("Variable", var, "assigned method: pmm (continuous)\n")
      } else if (var %in% nom_available) {
        unique_vals <- unique(data_for_mice[[var]][!is.na(data_for_mice[[var]])])
        n_categories <- length(unique_vals)
        
        # Convert to factor
        data_for_mice[[var]] <- as.factor(data_for_mice[[var]])
        categorical_vars_for_mice <- c(categorical_vars_for_mice, var)
        
        if (n_categories == 2) {
          imputation_methods[var] <- "logreg"  # Binary logistic regression
          cat("Variable", var, "assigned method: logreg (binary factor with", n_categories, "categories)\n")
        } else {
          imputation_methods[var] <- "polyreg"  # Polytomous logistic regression
          cat("Variable", var, "assigned method: polyreg (factor with", n_categories, "categories)\n")
        }
      } else {
        # If variable type is unclear, keep as numeric and use pmm
        data_for_mice[[var]] <- as.numeric(data_for_mice[[var]])
        imputation_methods[var] <- "pmm"
        cat("Variable", var, "assigned method: pmm (default - unclear type)\n")
      }
    }
    
    tryCatch({
      # Perform MICE imputation
      mice_result <- mice::mice(data_for_mice, 
                                m = 5,  # Number of imputations
                                method = imputation_methods,
                                printFlag = FALSE,
                                seed = 123)
      
      # Use the first completed dataset
      data_imputed <- mice::complete(mice_result, 1)
      
      # Convert categorical variables back to numeric for DIBmix
      for (var in categorical_vars_for_mice) {
        data_imputed[[var]] <- as.numeric(data_imputed[[var]])
      }
      
      cat("MICE imputation completed successfully\n")
      data <- data_imputed
      
    }, error = function(e) {
      cat("MICE imputation failed:", e$message, "\n")
      cat("Falling back to simple imputation methods\n")
      
      # Fallback: simple imputation
      for (var in vars_to_impute) {
        if (var %in% names(data) && sum(is.na(data[[var]])) > 0) {
          if (var %in% cont_available) {
            # Median imputation for continuous
            data[[var]][is.na(data[[var]])] <- median(data[[var]], na.rm = TRUE)
          } else {
            # Mode imputation for nominal/ordinal
            mode_val <- names(sort(table(data[[var]]), decreasing = TRUE))[1]
            data[[var]][is.na(data[[var]])] <- as.numeric(mode_val)
          }
        }
      }
      cat("Simple imputation completed for", length(vars_to_impute), "variables\n")
    })
  }
  
  # Final check: remove any cases that still have missing values
  final_missing_per_case <- rowSums(is.na(data))
  complete_cases <- final_missing_per_case == 0
  n_complete <- sum(complete_cases)
  
  if (n_complete < nrow(data)) {
    cat("Removing", nrow(data) - n_complete, "cases with remaining missing values\n")
    data <- data[complete_cases, , drop = FALSE]
  }
  
  cat("Final dataset:", nrow(data), "complete cases with", ncol(data), "variables\n")
  
  # Log transform highly skewed continuous variables
  skewed_vars <- c("HISEI", "HOMEPOS", "ICTRES", "SCHSIZE", "STRATIO")
  skewed_available <- intersect(skewed_vars, cont_available)
  
  for (v in skewed_available) {
    if (min(data[[v]], na.rm = TRUE) >= 0) {
      data[[v]] <- log(data[[v]] + 1)  # log(x+1) transformation
    }
  }
  
  # Ensure continuous variables are strictly numeric for DIBmix
  for (var in cont_available) {
    data[[var]] <- as.numeric(data[[var]])
  }
  
  # CRITICAL: Ensure we have at least one categorical variable for DIBmix
  if (length(nom_available) == 0) {
    cat("No natural categorical variables found. Creating categorical variables from continuous ones.\n")
    
    # Choose variables to categorize (prefer those with lower variation for stability)
    cont_vars_by_cv <- cont_available[order(sapply(cont_available, function(v) {
      cv <- sd(data[[v]], na.rm = TRUE) / mean(data[[v]], na.rm = TRUE)
      ifelse(is.finite(cv), cv, Inf)
    }))]
    
    vars_to_categorize <- cont_vars_by_cv[1:min(2, length(cont_vars_by_cv))]
    
    for (var in vars_to_categorize) {
      cat_var_name <- paste0(var, "_CAT")
      
      # Create categorical version by cutting into quartiles
      data[[cat_var_name]] <- as.integer(cut(data[[var]], 
                                             breaks = quantile(data[[var]], 
                                                               probs = c(0, 0.25, 0.5, 0.75, 1), na.rm = TRUE),
                                             include.lowest = TRUE))
      
      # Add to nominal variables and remove from continuous
      nom_available <- c(nom_available, cat_var_name)
      cont_available <- setdiff(cont_available, var)
      
      cat("Created categorical variable", cat_var_name, "from", var, "\n")
    }
  }
  
  # For nominal variables, ensure they are integers for DIBmix
  for (var in nom_available) {
    if (is.factor(data[[var]])) {
      data[[var]] <- as.integer(data[[var]])
    } else {
      data[[var]] <- as.integer(as.factor(data[[var]]))
    }
  }
  
  # Get column indices for DIBmix
  catcols <- which(names(data) %in% nom_available)
  contcols <- which(names(data) %in% cont_available)
  
  # Final validation
  if (length(catcols) == 0 || length(contcols) == 0) {
    stop("DIBmix requires at least one categorical and one continuous variable")
  }
  
  if (any(catcols %in% contcols)) {
    stop("Column indices overlap - this should not happen")
  }
  
  cat("Final preprocessing: continuous =", length(contcols), 
      ", categorical =", length(catcols), "\n")
  
  return(list(
    data = data,
    catcols = catcols,
    contcols = contcols
  ))
}
```

## DIBmix Clustering Analysis

### DIBmix Clustering Function

```{r}
# ---- DIBmix Clustering Function ----
perform_dibmix_clustering <- function(disadv_dt, cycle_year) {
  if (is.null(disadv_dt) || nrow(disadv_dt) == 0) return(NULL)
  
  # Prepare clustering data
  all_vars <- setdiff(names(disadv_dt), c("W_FSTUWT", "RESILIENT", "CYCLE", "CNTSCHID", "CNTSTUID"))
  cluster_data <- as.data.frame(disadv_dt[, all_vars, with = FALSE])
  
  cat("Running DIBmix clustering evaluation for", cycle_year, "...\n")
  cat("Data dimensions:", nrow(cluster_data), "students x", ncol(cluster_data), "variables\n")
  
  # Preprocess for DIBmix
  processed_result <- preprocess_for_dibmix_clustering(cluster_data)
  cluster_data_processed <- processed_result$data
  catcols <- processed_result$catcols
  contcols <- processed_result$contcols
  
  cat("After preprocessing:", nrow(cluster_data_processed), "students x", ncol(cluster_data_processed), "variables\n")
  
  # Test DIBmix with a small sample first
  tryCatch({
    
    # Run full DIBmix analysis
    dibmix_result <- clusterbenchstats(
      data = cluster_data_processed,
      G = K_RANGE,
      diss = FALSE,
      clustermethod = "dibmixCBI",
      methodnames = "DIBmix",
      distmethod = FALSE,
      ncinput = TRUE,
      clustermethodpars = list(list(catcols = catcols, contcols = contcols, lambda = -1, nstart = 100)),
      useboot = FALSE,
      trace = TRUE,
      nnruns = 100,
      kmruns = 100,
      fnruns = 100,
      avenruns = 100,
      useallg = TRUE,
      useallmethods = TRUE
    )
    
    cat("DIBmix clustering completed successfully for", cycle_year, "\n")
    return(dibmix_result)
    
  }, error = function(e) {
    cat("Error in DIBmix clustering for", cycle_year, ":", e$message, "\n")
    return(NULL)
  })
}
```

### Apply DIBmix to All Cycles

```{r}
# ---- Apply DIBmix Clustering to All Cycles ----
cat("\n=== DIBmix MIXED-TYPE CLUSTERING EVALUATION ===\n")
clustering_results_dibmix <- list()

for (cycle in names(processed_list)) {
  cat("\n--- Starting DIBmix clustering for", cycle, "---\n")
  
  if (is.null(processed_list[[cycle]]) || nrow(processed_list[[cycle]]) == 0) {
    cat("Warning: No valid data for cycle", cycle, "\n")
    next
  }
  
  result <- perform_dibmix_clustering(processed_list[[cycle]], cycle)
  if (!is.null(result)) {
    clustering_results_dibmix[[cycle]] <- result
  }
}

cat("\n=== CLUSTERING COMPLETED ===\n")
cat("Successful DIBmix analyses:", length(clustering_results_dibmix), "cycles\n")
```

## Cluster Validation and Optimal Solutions

### Extract and Analyze Optimal Clusterings

```{r}
# ---- Extract Optimal DIBmix Clusterings ----
optimal_dibmix_clusterings <- list()

for (cycle in names(clustering_results_dibmix)) {
  if (!is.null(clustering_results_dibmix[[cycle]])) {
    
    cat("\n=== DIBmix CLUSTERING VALIDATION RESULTS FOR", cycle, "===\n")
    
    # Print basic clustering results
    print(clustering_results_dibmix[[cycle]])
    
    # Extract statistics using the working function
    results_df <- extract_dibmix_statistics_master(clustering_results_dibmix[[cycle]])
    
    if (is.null(results_df)) {
      cat("Warning: Could not extract validation statistics for", cycle, "\n")
      next
    }
    
    cat("Extracted statistics for", nrow(results_df), "solutions:\n")
    print(results_df)
    
    # A1: Resilience Types Index
    weights_resilience <- create_resilience_weights_working(names(results_df), "resilience_types")
    A1_result <- NULL
    
    if (!is.null(weights_resilience)) {
      cat("\n--- RESILIENCE TYPES INDEX (A1) ---\n")
      cat("Purpose: Educational interpretation of resilience patterns\n")
      
      A1_result <- calculate_composite_index_working(results_df, weights_resilience)
      
      if (!is.null(A1_result)) {
        cat("Composite index results:\n")
        print(A1_result)
      } else {
        cat("Could not calculate A1 composite index\n")
      }
    }
    
    # A2: Student Matching Index
    weights_matching <- create_resilience_weights_working(names(results_df), "student_matching")
    A2_result <- NULL
    
    if (!is.null(weights_matching)) {
      cat("\n--- STUDENT MATCHING INDEX (A2) ---\n") 
      cat("Purpose: Finding students with very similar resilience profiles\n")
      
      A2_result <- calculate_composite_index_working(results_df, weights_matching)
      
      if (!is.null(A2_result)) {
        cat("Composite index results:\n")
        print(A2_result)
      } else {
        cat("Could not calculate A2 composite index\n")
      }
    }
    
    optimal_dibmix_clusterings[[cycle]] <- list(
      resilience_types = A1_result,
      student_matching = A2_result,
      full_results = clustering_results_dibmix[[cycle]]
    )
  }
}
```

### Fallback Simple Analysis

```{r}
# ---- Fallback Analysis if Composite Indices Fail ----
extract_simple_best_solutions_working <- function(cbs_result) {
  # Extract statistics using the master function
  results_df <- extract_dibmix_statistics_master(cbs_result)
  
  if (is.null(results_df)) {
    return(NULL)
  }
  
  # Simple ranking: prioritize silhouette width (asw) if available
  if ("asw" %in% names(results_df)) {
    results_df$simple_index <- results_df$asw
  } else if ("sindex" %in% names(results_df)) {
    results_df$simple_index <- results_df$sindex
  } else if ("pearsongamma" %in% names(results_df)) {
    results_df$simple_index <- results_df$pearsongamma
  } else {
    # Use any numeric column except k
    numeric_cols <- sapply(results_df, is.numeric)
    numeric_cols <- numeric_cols[!names(numeric_cols) %in% c("k")]
    
    if (any(numeric_cols)) {
      first_metric <- names(numeric_cols)[numeric_cols][1]
      results_df$simple_index <- results_df[[first_metric]]
    } else {
      return(NULL)
    }
  }
  
  # Sort by simple index
  results_df <- results_df[order(results_df$simple_index, decreasing = TRUE), ]
  
  return(results_df)
}

cat("\n=== FALLBACK: SIMPLE VALIDATION METRICS ANALYSIS ===\n")

simple_best_solutions <- list()

for (cycle in names(clustering_results_dibmix)) {
  if (!is.null(clustering_results_dibmix[[cycle]])) {
    
    simple_result <- extract_simple_best_solutions_working(clustering_results_dibmix[[cycle]])
    
    if (!is.null(simple_result)) {
      cat("\nSimple ranking for", cycle, ":\n")
      print(head(simple_result, 3))  # Show top 3 solutions
      
      simple_best_solutions[[cycle]] <- simple_result
    } else {
      cat("No valid statistics found for", cycle, "\n")
    }
  }
}
```

## Cross-Cycle Stability Analysis

```{r}
# ---- Cross-Cycle DIBmix Resilience Stability Analysis ----
if (length(optimal_dibmix_clusterings) > 1 || length(simple_best_solutions) > 1) {
  cat("\n=== CROSS-CYCLE DIBmix RESILIENCE PATTERN STABILITY ===\n")
  
  # Extract best solutions for resilience types
  best_resilience_solutions <- list()
  
  for (cycle in names(optimal_dibmix_clusterings)) {
    if (!is.null(optimal_dibmix_clusterings[[cycle]]$resilience_types)) {
      A1_results <- optimal_dibmix_clusterings[[cycle]]$resilience_types
      
      if (!is.null(A1_results) && nrow(A1_results) > 0) {
        best_row <- which.max(A1_results$index)
        best_method <- A1_results$method[best_row]
        best_k <- A1_results$k[best_row]
        best_index <- A1_results$index[best_row]
        
        best_resilience_solutions[[cycle]] <- list(
          method = best_method,
          k = best_k,
          index_value = best_index
        )
        
        cat("Cycle", cycle, "- Best resilience clustering: DIBmix", 
            "with k =", best_k, "(index =", round(best_index, 3), ")\n")
      }
    } else if (!is.null(simple_best_solutions[[cycle]])) {
      # Use simple ranking as fallback
      simple_best <- simple_best_solutions[[cycle]][1, ]
      best_resilience_solutions[[cycle]] <- list(
        method = "DIBmix",
        k = simple_best$k,
        index_value = simple_best$simple_index
      )
      
      cat("Cycle", cycle, "- Best resilience clustering: DIBmix", 
          "with k =", simple_best$k, "(simple metric =", round(simple_best$simple_index, 3), ")\n")
    }
  }
  
  # Analyze cross-cycle consistency
  if (length(best_resilience_solutions) > 1) {
    methods <- sapply(best_resilience_solutions, function(x) x$method)
    ks <- sapply(best_resilience_solutions, function(x) x$k)
    indices <- sapply(best_resilience_solutions, function(x) x$index_value)
    
    cat("\n--- Cross-cycle consistency analysis ---\n")
    cat("Clustering method: DIBmix (consistent across all cycles)\n")
    cat("Optimal k values:", paste(ks, collapse = ", "), "\n")
    cat("Index values:", paste(round(indices, 3), collapse = ", "), "\n")
    
    # Consistency checks
    k_consistent <- length(unique(ks)) == 1
    k_stable <- abs(max(ks) - min(ks)) <= 1
    
    cat("\nStability assessment:\n")
    cat("✓ Consistent clustering method (DIBmix) across all cycles\n")
    
    if (k_consistent) {
      cat("✓ Identical number of resilience clusters across all cycles\n")
    } else if (k_stable) {
      cat("✓ Stable number of resilience clusters (±1) across cycles\n")
    } else {
      cat("✗ Variable number of resilience clusters across cycles\n")
    }
    
    # Calculate stability metrics
    mean_index <- mean(indices)
    sd_index <- sd(indices)
    cv_index <- sd_index / mean_index
    
    cat("\nComposite index stability:\n")
    cat("Mean index value:", round(mean_index, 3), "\n")
    cat("Standard deviation:", round(sd_index, 3), "\n")
    cat("Coefficient of variation:", round(cv_index, 3), "\n")
    
    if (cv_index < 0.1) {
      cat("✓ Very stable clustering quality across cycles\n")
    } else if (cv_index < 0.2) {
      cat("✓ Moderately stable clustering quality across cycles\n")
    } else {
      cat("⚠ Variable clustering quality across cycles\n")
    }
  }
}
```

## Detailed Cluster Profiling

```{r}
# ---- Detailed DIBmix Cluster Profiling and Interpretation ----
if (length(optimal_dibmix_clusterings) > 0 || length(simple_best_solutions) > 0) {
  cat("\n=== DETAILED DIBmix RESILIENCE CLUSTER PROFILING ===\n")
  
  cycles_to_profile <- unique(c(names(optimal_dibmix_clusterings), names(simple_best_solutions)))
  
  for (cycle in cycles_to_profile) {
    best_result <- NULL
    best_k <- NULL
    
    # Try to get best solution from composite index first
    if (cycle %in% names(optimal_dibmix_clusterings) && 
        !is.null(optimal_dibmix_clusterings[[cycle]]$resilience_types)) {
      A1_results <- optimal_dibmix_clusterings[[cycle]]$resilience_types
      if (!is.null(A1_results) && nrow(A1_results) > 0) {
        best_row <- which.max(A1_results$index)
        best_k <- A1_results$k[best_row]
        best_result <- "composite"
      }
    }
    
    # Fallback to simple solution
    if (is.null(best_result) && cycle %in% names(simple_best_solutions)) {
      simple_best <- simple_best_solutions[[cycle]][1, ]
      best_k <- simple_best$k
      best_result <- "simple"
    }
    
    if (!is.null(best_k)) {
      cat("\n--- RESILIENCE PROFILES FOR", cycle, "---\n")
      cat("Best solution: DIBmix with", best_k, "clusters (", best_result, "ranking )\n")
      
      # Extract cluster assignments from the original clustering results
      if (cycle %in% names(clustering_results_dibmix)) {
        cm_results <- clustering_results_dibmix[[cycle]]$cm
        
        # Find the DIBmix clustering result for best k
        method_names <- names(cm_results)
        dibmix_index <- which(method_names == "DIBmix")
        
        if (length(dibmix_index) > 0) {
          method_results <- cm_results[[dibmix_index]]
          k_names <- names(method_results)
          k_index <- which(k_names == paste0("k", best_k))
          
          if (length(k_index) > 0) {
            cluster_assignments <- method_results[[k_index]]$partition
            
            # Get original data for profiling
            original_data <- processed_list[[cycle]]
            all_vars <- setdiff(names(original_data), 
                                c("W_FSTUWT", "RESILIENT", "CYCLE", "CNTSCHID", "CNTSTUID"))
            
            # Add cluster assignments to data
            profile_data <- original_data[, c(all_vars, "RESILIENT"), with = FALSE]
            profile_data$CLUSTER <- cluster_assignments
            
            # Create cluster profiles
            cluster_profiles <- profile_data[, lapply(.SD, function(x) {
              if (is.numeric(x)) {
                return(mean(x, na.rm = TRUE))
              } else {
                return(as.numeric(names(sort(table(x), decreasing = TRUE))[1]))
              }
            }), by = CLUSTER, .SDcols = c(all_vars, "RESILIENT")]
            
            # Display key profile characteristics
            cat("\nCluster characteristics (means):\n")
            
            # Focus on key resilience-related variables
            key_vars <- c("MATH_AVG", "READ_AVG", "SCIE_AVG", "ESCS", 
                          "RESILIENT", "ANXMAT", "BELONG", "TEACHSUP", "HOMEPOS")
            available_key_vars <- intersect(key_vars, names(cluster_profiles))
            
            if (length(available_key_vars) > 0) {
              profile_summary <- cluster_profiles[, c("CLUSTER", available_key_vars), with = FALSE]
              print(round(profile_summary, 3))
              
              # Export detailed cluster profiles
              profile_file <- paste0("cluster_profiles_", cycle, "_DIBmix_k", best_k, ".csv")
              fwrite(cluster_profiles, profile_file)
              cat("Detailed cluster profiles exported to:", profile_file, "\n")
            }
            
            # Resilience distribution by cluster
            resilience_by_cluster <- profile_data[, .(
              N = .N,
              Resilient_N = sum(RESILIENT, na.rm = TRUE),
              Resilient_Prop = mean(RESILIENT, na.rm = TRUE),
              Math_Achievement = mean(MATH_AVG, na.rm = TRUE),
              Read_Achievement = mean(READ_AVG, na.rm = TRUE),
              Science_Achievement = mean(SCIE_AVG, na.rm = TRUE),
              SES = mean(ESCS, na.rm = TRUE)
            ), by = CLUSTER]
            
            cat("\nResilience distribution by cluster:\n")
            print(round(resilience_by_cluster, 3))
            
            # Identify high-resilience clusters
            high_resilience_clusters <- resilience_by_cluster[Resilient_Prop > 0.5]$CLUSTER
            if (length(high_resilience_clusters) > 0) {
              cat("High-resilience clusters (>50% resilient students):", 
                  paste(high_resilience_clusters, collapse = ", "), "\n")
            }
            
            # Export individual student cluster assignments
            assignments_data <- original_data[, .(CYCLE, CNTSCHID, CNTSTUID, RESILIENT)]
            assignments_data$CLUSTER <- cluster_assignments
            assignments_data$METHOD <- "DIBmix"
            assignments_data$K <- best_k
            
            assignments_file <- paste0("student_cluster_assignments_", cycle, ".csv")
            fwrite(assignments_data, assignments_file)
            cat("Student cluster assignments exported to:", assignments_file, "\n")
          } else {
            cat("Could not find k =", best_k, "results for DIBmix\n")
          }
        } else {
          cat("Could not find DIBmix results\n")
        }
      }
    } else {
      cat("No valid clustering solution found for", cycle, "\n")
    }
  }
}
```

## Visualization

```{r}
# ---- Corrected Visualization Functions ----
create_dibmix_cluster_visualizations <- function(cycle, optimal_result, processed_data, simple_result = NULL) {
  
  # Determine best k from either composite or simple results
  best_k <- NULL
  best_method <- "DIBmix"
  
  if (!is.null(optimal_result) && !is.null(optimal_result$resilience_types)) {
    A1_results <- optimal_result$resilience_types
    if (!is.null(A1_results) && nrow(A1_results) > 0) {
      best_row <- which.max(A1_results$index)
      best_k <- A1_results$k[best_row]
    }
  }
  
  if (is.null(best_k) && !is.null(simple_result)) {
    best_k <- simple_result[1, ]$k
  }
  
  if (is.null(best_k)) {
    cat("Could not determine best k for visualizations\n")
    return(NULL)
  }
  
  cat("Creating visualizations for", cycle, "with DIBmix k =", best_k, "\n")
  
  # Extract cluster assignments
  if (!cycle %in% names(clustering_results_dibmix)) {
    cat("No clustering results available for", cycle, "\n")
    return(NULL)
  }
  
  cm_results <- clustering_results_dibmix[[cycle]]$cm
  dibmix_index <- which(names(cm_results) == "DIBmix")
  
  if (length(dibmix_index) == 0) {
    cat("Could not find DIBmix clustering results for visualization\n")
    return(NULL)
  }
  
  cluster_assignments <- cm_results[[dibmix_index]][[paste0("k", best_k)]]$partition
  
  # Prepare data for visualization
  all_vars <- setdiff(names(processed_data), 
                      c("W_FSTUWT", "RESILIENT", "CYCLE", "CNTSCHID", "CNTSTUID"))
  viz_data <- processed_data[, c(all_vars, "RESILIENT"), with = FALSE]
  viz_data$CLUSTER <- as.factor(cluster_assignments)
  viz_data$RESILIENT <- as.factor(viz_data$RESILIENT)
  
  # 1. Mathematics Achievement by cluster and resilience status
  if (all(c("MATH_AVG", "RESILIENT") %in% names(viz_data))) {
    
    p1 <- ggplot(viz_data, aes(x = CLUSTER, y = MATH_AVG, fill = RESILIENT)) +
      geom_boxplot(alpha = 0.7) +
      scale_fill_manual(values = c("0" = "#E74C3C", "1" = "#27AE60"), 
                        labels = c("Non-Resilient", "Resilient"),
                        name = "Student Type") +
      labs(title = paste("Mathematics Achievement Distribution by DIBmix Cluster -", cycle),
           subtitle = paste("Optimal DIBmix clustering with", best_k, "clusters | Resilience = Level 3+ all domains"),
           x = "Cluster", y = "Mathematics Achievement Score") +
      theme_minimal() +
      theme(legend.position = "bottom")
    
    ggsave(paste0("math_achievement_by_dibmix_cluster_", cycle, ".png"), p1, width = 10, height = 6)
    print(p1)
  }
  
  # 2. Cluster composition (resilience proportions)
  cluster_composition <- viz_data[, .(
    Total = .N,
    Resilient = sum(as.numeric(as.character(RESILIENT))),
    Prop_Resilient = mean(as.numeric(as.character(RESILIENT)))
  ), by = CLUSTER]
  
  p2 <- ggplot(cluster_composition, aes(x = CLUSTER, y = Prop_Resilient, fill = CLUSTER)) +
    geom_col(alpha = 0.8) +
    geom_text(aes(label = paste0(round(Prop_Resilient * 100, 1), "%")), 
              vjust = -0.5, size = 3.5) +
    scale_fill_viridis_d(name = "Cluster") +
    scale_y_continuous(labels = scales::percent_format(), limits = c(0, 1)) +
    labs(title = paste("Resilience Proportions by DIBmix Cluster -", cycle),
         subtitle = paste("Total students:", nrow(viz_data), "| Resilience = PISA Level 3+ in Math, Reading & Science"),
         x = "Cluster", y = "Proportion of Resilient Students") +
    theme_minimal() +
    theme(legend.position = "none")
  
  ggsave(paste0("resilience_proportions_dibmix_", cycle, ".png"), p2, width = 8, height = 6)
  print(p2)
  
  # 3. SES vs Mathematics Achievement by cluster
  if (all(c("ESCS", "MATH_AVG") %in% names(viz_data))) {
    
    p3 <- ggplot(viz_data, aes(x = ESCS, y = MATH_AVG, color = CLUSTER, shape = RESILIENT)) +
      geom_point(alpha = 0.6, size = 2) +
      scale_color_viridis_d(name = "Cluster") +
      scale_shape_manual(values = c("0" = 1, "1" = 16), 
                         labels = c("Non-Resilient", "Resilient"),
                         name = "Student Type") +
      labs(title = paste("SES vs Mathematics Achievement by DIBmix Cluster -", cycle),
           subtitle = "DIBmix clustering for mixed-type resilience data",
           x = "Socioeconomic Status (ESCS)", y = "Mathematics Achievement") +
      theme_minimal() +
      theme(legend.position = "bottom")
    
    ggsave(paste0("ses_math_achievement_dibmix_clusters_", cycle, ".png"), p3, width = 10, height = 8)
    print(p3)
  }
  
  cat("DIBmix visualizations saved for", cycle, "\n")
}
```

### Generate Visualizations

```{r}
# ---- Generate Visualizations for All Cycles ----
cycles_to_visualize <- unique(c(names(optimal_dibmix_clusterings), names(simple_best_solutions)))

if (length(cycles_to_visualize) > 0) {
  cat("\n=== GENERATING DIBmix CLUSTER VISUALIZATIONS ===\n")
  
  for (cycle in cycles_to_visualize) {
    if (!is.null(processed_list[[cycle]])) {
      tryCatch({
        optimal_result <- if (cycle %in% names(optimal_dibmix_clusterings)) optimal_dibmix_clusterings[[cycle]] else NULL
        simple_fallback <- if (cycle %in% names(simple_best_solutions)) simple_best_solutions[[cycle]] else NULL
        create_dibmix_cluster_visualizations(cycle, optimal_result, processed_list[[cycle]], simple_fallback)
      }, error = function(e) {
        cat("Error creating visualizations for", cycle, ":", e$message, "\n")
      })
    }
  }
}
```

## Results Export and Summary

```{r}
# ---- Export Results and Create Summary ----
cat("\n=== DIBmix CLUSTERING ANALYSIS SUMMARY ===\n")
cat("==========================================\n")
cat("Methodology: DIBmix mixed-type clustering with Akhanli & Hennig validation\n")
cat("Framework: clusterbenchstats with composite validity indexes\n")
cat("Data: PISA disadvantaged students, Greece,", length(pisa_cycles), "cycles\n")
cat("Resilience Definition: PISA Level 3+ in all three domains (Math≥482.38, Read≥480.18, Science≥484.14)\n\n")

# Summary statistics
total_students <- sum(sapply(processed_list, function(x) if (!is.null(x)) nrow(x) else 0))
successful_cycles <- length(clustering_results_dibmix)

cat("Data Summary:\n")
cat("- Total disadvantaged students analyzed:", total_students, "\n")
cat("- Successful DIBmix clustering cycles:", successful_cycles, "out of", length(pisa_cycles), "\n")
cat("- Clustering range evaluated: k =", min(K_RANGE), "to", max(K_RANGE), "\n")
cat("- Method: DIBmix only (optimized for mixed-type educational data)\n\n")

# Best solutions summary
has_composite_results <- FALSE
has_simple_results <- FALSE

if (length(optimal_dibmix_clusterings) > 0) {
  cat("Optimal DIBmix Resilience Clustering Solutions:\n")
  
  for (cycle in names(optimal_dibmix_clusterings)) {
    if (!is.null(optimal_dibmix_clusterings[[cycle]]$resilience_types)) {
      A1_results <- optimal_dibmix_clusterings[[cycle]]$resilience_types
      if (!is.null(A1_results) && nrow(A1_results) > 0) {
        best_row <- which.max(A1_results$index)
        best_k <- A1_results$k[best_row]
        best_index <- A1_results$index[best_row]
        
        cat("-", cycle, ": DIBmix with k =", best_k, 
            "(Composite Index =", round(best_index, 3), ")\n")
        has_composite_results <- TRUE
      }
    }
  }
}

if (length(simple_best_solutions) > 0) {
  cat("\nSimple Metric Solutions (fallback approach):\n")
  
  for (cycle in names(simple_best_solutions)) {
    if (!cycle %in% names(optimal_dibmix_clusterings) || 
        is.null(optimal_dibmix_clusterings[[cycle]]$resilience_types)) {
      simple_best <- simple_best_solutions[[cycle]][1, ]
      cat("-", cycle, ": DIBmix with k =", simple_best$k, 
          "(Simple metric =", round(simple_best$simple_index, 3), ")\n")
      has_simple_results <- TRUE
    }
  }
}

# Save results
saveRDS(optimal_dibmix_clusterings, "dibmix_clustering_results.rds")
saveRDS(clustering_results_dibmix, "full_dibmix_clusterbenchstats_results.rds")

if (length(simple_best_solutions) > 0) {
  saveRDS(simple_best_solutions, "simple_dibmix_solutions.rds")
}

cat("\nFiles Generated:\n")
cat("- dibmix_clustering_results.rds: Complete optimal DIBmix clustering results\n")
cat("- full_dibmix_clusterbenchstats_results.rds: Detailed validation statistics\n")
cat("- cluster_profiles_[cycle]_DIBmix_k[k].csv: Cluster characteristic profiles\n")
cat("- student_cluster_assignments_[cycle].csv: Individual student assignments\n")
cat("- achievement_by_dibmix_cluster_[cycle].png: Achievement distribution plots\n")
cat("- resilience_proportions_dibmix_[cycle].png: Resilience composition plots\n")
cat("- ses_achievement_dibmix_clusters_[cycle].png: SES vs Achievement scatter plots\n")

cat("\nDIBmix results saved successfully!\n")
```

## Helper Functions for Post-Analysis

```{r}
# ---- Helper Functions for Additional Analysis ----

#' Examine DIBmix Results
#' Quick overview of clustering results
examine_dibmix_results <- function() {
  cat("=== HELPER: EXAMINING DIBMIX RESULTS ===\n")
  
  if (file.exists("dibmix_clustering_results.rds")) {
    results <- readRDS("dibmix_clustering_results.rds")
    cat("Loaded optimal clustering results for", length(results), "cycles\n")
    
    for (cycle in names(results)) {
      cat("\nCycle", cycle, ":\n")
      if (!is.null(results[[cycle]]$resilience_types)) {
        best_k <- results[[cycle]]$resilience_types$k[which.max(results[[cycle]]$resilience_types$index)]
        best_index <- max(results[[cycle]]$resilience_types$index)
        cat("  Best k:", best_k, "with composite index:", round(best_index, 3), "\n")
      } else {
        cat("  No composite index results available\n")
      }
    }
  } else {
    cat("No results file found. Run the analysis first.\n")
  }
}

#' Create Summary Report
#' Generate a comprehensive summary CSV
create_summary_report <- function() {
  if (!file.exists("dibmix_clustering_results.rds")) {
    cat("No results available. Run analysis first.\n")
    return(NULL)
  }
  
  results <- readRDS("dibmix_clustering_results.rds")
  
  summary_report <- data.frame(
    Cycle = character(),
    Best_K = numeric(),
    Composite_Index = numeric(),
    Method = character(),
    stringsAsFactors = FALSE
  )
  
  for (cycle in names(results)) {
    if (!is.null(results[[cycle]]$resilience_types)) {
      A1_results <- results[[cycle]]$resilience_types
      best_row <- which.max(A1_results$index)
      
      summary_report <- rbind(summary_report, data.frame(
        Cycle = cycle,
        Best_K = A1_results$k[best_row],
        Composite_Index = A1_results$index[best_row],
        Method = "DIBmix",
        stringsAsFactors = FALSE
      ))
    }
  }
  
  # Save summary report
  write.csv(summary_report, "dibmix_summary_report.csv", row.names = FALSE)
  cat("Summary report saved to dibmix_summary_report.csv\n")
  
  return(summary_report)
}

#' Compare Cluster Profiles Across Cycles
#' Combine and analyze cluster profiles from all cycles
compare_cluster_profiles_across_cycles <- function() {
  if (!file.exists("dibmix_clustering_results.rds")) {
    cat("No results available. Run analysis first.\n")
    return(NULL)
  }
  
  # Look for cluster profile files
  profile_files <- list.files(pattern = "cluster_profiles_.*_DIBmix_k.*\\.csv")
  
  if (length(profile_files) == 0) {
    cat("No cluster profile files found.\n")
    return(NULL)
  }
  
  cat("Found", length(profile_files), "cluster profile files:\n")
  print(profile_files)
  
  # Load and combine profiles
  all_profiles <- list()
  
  for (file in profile_files) {
    # Extract cycle and k from filename
    cycle_match <- regmatches(file, regexpr("\\d{4}", file))
    k_match <- regmatches(file, regexpr("k\\d+", file))
    k_value <- as.numeric(gsub("k", "", k_match))
    
    profiles <- read.csv(file)
    profiles$CYCLE <- cycle_match
    profiles$K <- k_value
    profiles$SOURCE_FILE <- file
    
    all_profiles[[file]] <- profiles
  }
  
  # Combine all profiles
  combined_profiles <- do.call(rbind, all_profiles)
  
  # Save combined profiles
  write.csv(combined_profiles, "combined_cluster_profiles_across_cycles.csv", row.names = FALSE)
  cat("Combined cluster profiles saved to combined_cluster_profiles_across_cycles.csv\n")
  
  return(combined_profiles)
}

#' Create Cluster Interpretation Report
#' Generate detailed interpretive descriptions
create_cluster_interpretation_report <- function() {
  cat("=== CREATING CLUSTER INTERPRETATION REPORT ===\n")
  
  if (!file.exists("dibmix_clustering_results.rds")) {
    cat("No results available. Run analysis first.\n")
    return(NULL)
  }
  
  results <- readRDS("dibmix_clustering_results.rds")
  
  # Create interpretation report
  interpretation_report <- list()
  
  for (cycle in names(results)) {
    if (!is.null(results[[cycle]]$resilience_types)) {
      A1_results <- results[[cycle]]$resilience_types
      best_k <- A1_results$k[which.max(A1_results$index)]
      
      # Look for corresponding profile file
      profile_file <- paste0("cluster_profiles_", cycle, "_DIBmix_k", best_k, ".csv")
      
      if (file.exists(profile_file)) {
        profiles <- read.csv(profile_file)
        
        # Create interpretive descriptions for each cluster
        cluster_descriptions <- list()
        
        for (cluster_id in unique(profiles$CLUSTER)) {
          cluster_data <- profiles[profiles$CLUSTER == cluster_id, ]
          
          # Extract key characteristics
          resilience_rate <- if ("RESILIENT" %in% names(cluster_data)) {
            round(cluster_data$RESILIENT * 100, 1)
          } else NA
          
          math_achievement <- if ("MATH_AVG" %in% names(cluster_data)) {
            round(cluster_data$MATH_AVG, 1)
          } else NA
          
          read_achievement <- if ("READ_AVG" %in% names(cluster_data)) {
            round(cluster_data$READ_AVG, 1)
          } else NA
          
          science_achievement <- if ("SCIE_AVG" %in% names(cluster_data)) {
            round(cluster_data$SCIE_AVG, 1)
          } else NA
          
          ses <- if ("ESCS" %in% names(cluster_data)) {
            round(cluster_data$ESCS, 2)
          } else NA
          
         
         # Create description
          description <- paste0(
            "Cluster ", cluster_id, " (", cycle, "): ",
            if (!is.na(resilience_rate)) paste0(resilience_rate, "% resilient, ") else "",
            if (!is.na(math_achievement)) paste0("Math: ", math_achievement, ", ") else "",
            if (!is.na(read_achievement)) paste0("Read: ", read_achievement, ", ") else "",
            if (!is.na(science_achievement)) paste0("Science: ", science_achievement, ", ") else "",
            if (!is.na(ses)) paste0("SES: ", ses) else ""
          )
          
          cluster_descriptions[[paste0("Cluster_", cluster_id)]] <- description
        }
        
        interpretation_report[[cycle]] <- cluster_descriptions
      }
    }
  }
  
  # Save interpretation report
  interpretation_text <- ""
  for (cycle in names(interpretation_report)) {
    interpretation_text <- paste0(interpretation_text, "\n=== ", cycle, " ===\n")
    for (cluster in names(interpretation_report[[cycle]])) {
      interpretation_text <- paste0(interpretation_text, interpretation_report[[cycle]][[cluster]], "\n")
    }
  }
  
  writeLines(interpretation_text, "cluster_interpretation_report.txt")
  cat("Cluster interpretation report saved to cluster_interpretation_report.txt\n")
  
  return(interpretation_report)
}

# Print helper function information
cat("\n=== HELPER FUNCTIONS AVAILABLE ===\n")
cat("After running the analysis, you can use these functions:\n")
cat("1. examine_dibmix_results() - Quick overview of results\n")
cat("2. create_summary_report() - Generate summary CSV\n") 
cat("3. compare_cluster_profiles_across_cycles() - Combine all cluster profiles\n")
cat("4. create_cluster_interpretation_report() - Generate interpretive descriptions\n\n")
```

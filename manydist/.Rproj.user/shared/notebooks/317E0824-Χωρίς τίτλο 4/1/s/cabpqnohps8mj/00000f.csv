"0","#Data Loading and Processing"
"0","cat(""\n=== LOADING AND PROCESSING PISA DATA ===\n"")"
"1","
=== LOADING AND PROCESSING PISA DATA ===
"
"0","# ---- Required Packages ----"
"0","library(haven)"
"0","library(data.table)"
"0","library(mice)"
"0",""
"0","# ---- PISA Cycle Configuration ----"
"0","pisa_cycles <- list("
"0","  ""2015"" = list("
"0","    student_file = ""CY6_MS_CMB_STU_QQQ.sav"","
"0","    school_file = ""CY6_MS_CMB_SCH_QQQ.sav"","
"0","    year = 2015,"
"0","    var_mapping = list("
"0","      student = c(""PARED"" = ""PAREDINT""),"
"0","      school = c()"
"0","    )"
"0","  ),"
"0","  ""2018"" = list("
"0","    student_file = ""CY07_MSU_STU_QQQ.sav"","
"0","    school_file = ""CY07_MSU_SCH_QQQ.sav"","
"0","    year = 2018,"
"0","    var_mapping = list("
"0","      student = c(),"
"0","      school = c(""STRATIO"" = ""STRATIO"")"
"0","    )"
"0","  ),"
"0","  ""2022"" = list("
"0","    student_file = ""CY08MSP_STU_QQQ.sav"","
"0","    school_file = ""CY08MSP_SCH_QQQ.sav"","
"0","    year = 2022,"
"0","    var_mapping = list("
"0","      student = c(),"
"0","      school = c(""SMRATIO"" = ""STRATIO"")"
"0","    )"
"0","  )"
"0",")"
"0",""
"0","core_student_vars <- list("
"0","  ids = c(""CNT"", ""CNTSCHID"", ""CNTSTUID""),"
"0","  achievement = c(paste0(""PV"", 1:10, ""MATH""), paste0(""PV"", 1:10, ""READ""), paste0(""PV"", 1:10, ""SCIE"")),"
"0","  ses_background = c(""ESCS"", ""HISEI"", ""PAREDINT"", ""HOMEPOS"", ""ICTRES"", ""WEALTH"", ""HEDRES""),"
"0","  demographics = c(""ST004D01T"", ""IMMIG"", ""REPEAT""),"
"0","  motivation = c("
"0","    ""ANXTEST"", ""ANXMAT"", ""MATHMOT"", ""MATHEFF"", ""SCIEEFF"", ""JOYSCIE"", ""INTMAT"","
"0","    ""WORKMAST"", ""MASTGOAL"", ""GFOFAIL"", ""COMPETE"","
"0","    ""INTBRSCI"", ""INSTSCIE"", ""MOTIVAT"", ""JOYREAD"","
"0","    ""INTSCIE"", ""READINTEREST"", ""GLOBCOMP"", ""MATHINT"""
"0","  ),"
"0","  psychological = c("
"0","    ""PERSEV"", ""WORKMAST"", ""COMPETE"", ""EPIST"", ""BELONG"","
"0","    ""GCSELFEFF"", ""METASUM"", ""ADAPTIVITY"", ""PERSEVAGR"", ""GROSAGR"", ""STRESAGR"","
"0","    ""EMOCOAGR"", ""CURIOAGR"", ""COOPAGR"", ""EMPATAGR"", ""ASSERAGR"", ""CREATBELIEF"""
"0","  ),"
"0","  social_support = c("
"0","    ""TEACHSUP"", ""BELONG"", ""FAMSUP"", ""RELATST"", ""EMOSUPS"", ""EMOSUPSCI"", ""CURSUPP"","
"0","    ""BEINGBULLIED"", ""BULLIED"", ""FEELSAFE"", ""SOCCON"", ""SOCONPA"", ""PARINVOL"", ""PARSUPMAT"""
"0","  ),"
"0","  learning_behavior = c("
"0","    ""HOMWRK"", ""PERFEED"", ""DISCLIMA"", ""DISCLISCI"", ""DIRINS"", ""TRUANCY"","
"0","    ""ADINST"", ""SMINS"", ""SADDINST"", ""STUDYHMW"", ""EXERPRAC"","
"0","    ""WORKPAY"", ""WORKHOME"", ""SKIPPING"", ""TARDYSD"", ""COGACRCO"", ""COGACMCO"","
"0","    ""EXPOFA"", ""EXPO21ST"", ""DIGLRN"""
"0","  ),"
"0","  wellbeing = c("
"0","    ""LIFESAT"", ""ATTSCHL"", ""EUDMO"", ""SWBP"", ""PSYCHSYM"", ""SOCCON"", ""BODYIMA"", ""EXPWB"""
"0","  ),"
"0","  perceptions = c(""PQSCHOOL"", ""PISADIFF"", ""PQMOTHER"", ""PQFATHER""),"
"0","  weights = ""W_FSTUWT"""
"0",")"
"0",""
"0","core_school_vars <- list("
"0","  ids = c(""CNT"", ""CNTSCHID""),"
"0","  characteristics = c("
"0","    ""SCHSIZE"", ""SCHLTYPE"", ""STRATIO"", ""PRIVATESCH"", ""CLSIZE"", ""SMRATIO"""
"0","  ),"
"0","  resources = c("
"0","    ""STAFFSHORT"", ""EDUSHORT"", ""RATCMP1"", ""SCIERES"", ""CREACTIV"", ""RATCMP2"","
"0","    ""TOTAT"", ""DIGRES"""
"0","  ),"
"0","  teacher_quality = c("
"0","    ""PROAT5AB"", ""PROAT5AM"", ""PROAT6"", ""PROATCE"", ""PROSTAT"", ""PROSTCE"","
"0","    ""PROSTMAS"", ""PROATCE"", ""SCIENTCH"", ""TCHENTHU"", ""TCHFAIR"", ""TCHSUPPORT"""
"0","  ),"
"0","  school_climate = c("
"0","    ""STUBEHA"", ""TEACHBEHA"", ""SCMCEG"", ""NEGSCLIM"", ""ENCOURPG"""
"0","  ),"
"0","  leadership = c(""LEAD"", ""LEADPD"", ""LEADTCH"", ""SCHAUT"", ""TEACHPART"", ""INSTLEAD"", ""TCHPART""),"
"0","  community = c(""SCHCOM"", ""PARPART"", ""EQUITYPOL"", ""CREATCURR""),"
"0","  weights = ""W_SCHGRNRABWT"""
"0",")"
"0",""
"0","# ---- File Reading Function ----"
"0","safe_read_pisa_with_mapping <- function(file_path, var_list, var_mapping,"
"0","                                        target_countries = NULL, cycle_year = NULL) {"
"0","  tryCatch({"
"0","    file_vars <- names(read_sav(file_path, n_max = 0))"
"0","    reverse_mapping <- setNames(names(var_mapping), var_mapping)"
"0","    vars_to_request <- sapply(var_list, function(std_var) {"
"0","      if (std_var %in% names(reverse_mapping)) {"
"0","        reverse_mapping[[std_var]]"
"0","      } else {"
"0","        std_var"
"0","      }"
"0","    })"
"0","    available_vars <- intersect(vars_to_request, file_vars)"
"0","    if (length(available_vars) == 0) {"
"0","      warning(""No requested variables found in "", basename(file_path))"
"0","      return(NULL)"
"0","    }"
"0","    dt <- setDT(read_sav(file_path, col_select = any_of(available_vars)))"
"0","    for (old_name in names(var_mapping)) {"
"0","      new_name <- var_mapping[[old_name]]"
"0","      if (old_name %in% names(dt)) {"
"0","        setnames(dt, old_name, new_name)"
"0","      }"
"0","    }"
"0","    if (!is.null(target_countries) && ""CNT"" %in% names(dt)) {"
"0","      dt <- dt[CNT %in% target_countries]"
"0","    }"
"0","    if (!is.null(cycle_year)) {"
"0","      dt[, CYCLE := cycle_year]"
"0","    }"
"0","    return(dt)"
"0","  }, error = function(e) {"
"0","    cat(""Error reading file:"", basename(file_path), "" - "", e$message, ""\n"")"
"0","    return(NULL)"
"0","  })"
"0","}"
"0",""
"0","# ---- Load All PISA Cycles ----"
"0","all_student_vars <- unlist(core_student_vars, use.names = FALSE)"
"0","all_school_vars <- unlist(core_school_vars, use.names = FALSE)"
"0","pisa_student_list <- list()"
"0","pisa_school_list <- list()"
"0","for (cycle_name in names(pisa_cycles)) {"
"0","  cycle_info <- pisa_cycles[[cycle_name]]"
"0","  cat(""\n--- Loading PISA"", cycle_info$year, ""---\n"")"
"0","  stu_file <- path(cycle_info$student_file)"
"0","  stu_data <- safe_read_pisa_with_mapping("
"0","    stu_file, all_student_vars, cycle_info$var_mapping$student,"
"0","    target_countries, cycle_info$year"
"0","  )"
"0","  if (!is.null(stu_data) && nrow(stu_data) > 0) {"
"0","    pisa_student_list[[cycle_name]] <- stu_data"
"0","    cat(""Students loaded:"", nrow(stu_data), ""\n"")"
"0","  } else {"
"0","    cat(""No student data loaded for"", cycle_name, ""\n"")"
"0","  }"
"0","  sch_file <- path(cycle_info$school_file)"
"0","  sch_data <- safe_read_pisa_with_mapping("
"0","    sch_file, all_school_vars, cycle_info$var_mapping$school,"
"0","    target_countries, cycle_info$year"
"0","  )"
"0","  if (!is.null(sch_data) && nrow(sch_data) > 0) {"
"0","    pisa_school_list[[cycle_name]] <- sch_data"
"0","    cat(""Schools loaded:"", nrow(sch_data), ""\n"")"
"0","  } else {"
"0","    cat(""No school data loaded for"", cycle_name, ""\n"")"
"0","  }"
"0","}"
"1","
--- Loading PISA"
"1"," "
"1","2015"
"1"," "
"1","---
"
"1","Error reading file:"
"1"," "
"1","CY6_MS_CMB_STU_QQQ.sav"
"1"," "
"1"," - "
"1"," "
"1","'/path/to/your/pisa/data/CY6_MS_CMB_STU_QQQ.sav' does not exist."
"1"," "
"1","
"
"1","No student data loaded for"
"1"," "
"1","2015"
"1"," "
"1","
"
"1","Error reading file:"
"1"," "
"1","CY6_MS_CMB_SCH_QQQ.sav"
"1"," "
"1"," - "
"1"," "
"1","'/path/to/your/pisa/data/CY6_MS_CMB_SCH_QQQ.sav' does not exist."
"1"," "
"1","
"
"1","No school data loaded for"
"1"," "
"1","2015"
"1"," "
"1","
"
"1","
--- Loading PISA"
"1"," "
"1","2018"
"1"," "
"1","---
"
"1","Error reading file:"
"1"," "
"1","CY07_MSU_STU_QQQ.sav"
"1"," "
"1"," - "
"1"," "
"1","'/path/to/your/pisa/data/CY07_MSU_STU_QQQ.sav' does not exist."
"1"," "
"1","
"
"1","No student data loaded for"
"1"," "
"1","2018"
"1"," "
"1","
"
"1","Error reading file:"
"1"," "
"1","CY07_MSU_SCH_QQQ.sav"
"1"," "
"1"," - "
"1"," "
"1","'/path/to/your/pisa/data/CY07_MSU_SCH_QQQ.sav' does not exist."
"1"," "
"1","
"
"1","No school data loaded for"
"1"," "
"1","2018"
"1"," "
"1","
"
"1","
--- Loading PISA"
"1"," "
"1","2022"
"1"," "
"1","---
"
"1","Error reading file:"
"1"," "
"1","CY08MSP_STU_QQQ.sav"
"1"," "
"1"," - "
"1"," "
"1","'/path/to/your/pisa/data/CY08MSP_STU_QQQ.sav' does not exist."
"1"," "
"1","
"
"1","No student data loaded for"
"1"," "
"1","2022"
"1"," "
"1","
"
"1","Error reading file:"
"1"," "
"1","CY08MSP_SCH_QQQ.sav"
"1"," "
"1"," - "
"1"," "
"1","'/path/to/your/pisa/data/CY08MSP_SCH_QQQ.sav' does not exist."
"1"," "
"1","
"
"1","No school data loaded for"
"1"," "
"1","2022"
"1"," "
"1","
"
"0","# ---- Process PISA Cycle with Imputation and Binary Resilience Indicators ----"
"0","process_pisa_cycle <- function(stu_dt, sch_dt, cycle_year) {"
"0","  if (is.null(stu_dt) || nrow(stu_dt) == 0) {"
"0","    cat(sprintf(""Error: No valid student data for cycle %s\n"", cycle_year))"
"0","    return(NULL)"
"0","  }"
"0","  "
"0","  # Check missingness in plausible values and SES variables"
"0","  cat(sprintf(""Missing MATH plausible values: %d, READ: %d, SCIE: %d\n"","
"0","              sum(rowSums(is.na(stu_dt[, .SD, .SDcols = patterns(""MATH$"")])) > 0),"
"0","              sum(rowSums(is.na(stu_dt[, .SD, .SDcols = patterns(""READ$"")])) > 0),"
"0","              sum(rowSums(is.na(stu_dt[, .SD, .SDcols = patterns(""SCIE$"")])) > 0)))"
"0","  cat(sprintf(""Missing ESCS: %d, HISEI: %d, HOMEPOS: %d, WEALTH: %d\n"","
"0","              sum(is.na(stu_dt$ESCS)),"
"0","              sum(is.na(stu_dt$HISEI)),"
"0","              sum(is.na(stu_dt$HOMEPOS)),"
"0","              sum(is.na(stu_dt$WEALTH))))"
"0","  "
"0","  # Impute ESCS if missingness is <= 30%"
"0","  escs_missing_pct <- mean(is.na(stu_dt$ESCS)) * 100"
"0","  cat(sprintf(""ESCS missingness: %.1f%%\n"", escs_missing_pct))"
"0","  if (escs_missing_pct > 0 && escs_missing_pct <= 30) {"
"0","    cat(""â†’ Imputing ESCS using MICE...\n"")"
"0","    ses_vars <- intersect(names(stu_dt), c(""ESCS"", ""HISEI"", ""PAREDINT"", ""HOMEPOS"", ""WEALTH"", ""ICTRES"", ""HEDRES""))"
"0","    mice_data <- as.data.frame(stu_dt[, ses_vars, with = FALSE])"
"0","    mice_methods <- make.method(mice_data)"
"0","    mice_methods[""ESCS""] <- ""pmm"""
"0","    tryCatch({"
"0","      mice_result <- mice(mice_data, m = 5, method = mice_methods, printFlag = FALSE, seed = 42)"
"0","      completed_mice <- complete(mice_result, 1)"
"0","      stu_dt[, ESCS := completed_mice$ESCS]"
"0","      cat(""âœ“ ESCS imputation completed\n"")"
"0","    }, error = function(e) {"
"0","      cat(sprintf(""ERROR in ESCS imputation for cycle %s: %s\n"", cycle_year, e$message))"
"0","    })"
"0","  } else if (escs_missing_pct > 30) {"
"0","    cat(""âš  ESCS missingness >30%, skipping imputation\n"")"
"0","  }"
"0","  "
"0","  # Impute SCIE plausible values if missingness is <= 30%"
"0","  scie_missing_pct <- mean(rowSums(is.na(stu_dt[, .SD, .SDcols = patterns(""SCIE$"")])) > 0) * 100"
"0","  cat(sprintf(""SCIE plausible values missingness: %.1f%%\n"", scie_missing_pct))"
"0","  if (scie_missing_pct > 0 && scie_missing_pct <= 30) {"
"0","    cat(""â†’ Imputing SCIE plausible values using MICE...\n"")"
"0","    scie_vars <- c(paste0(""PV"", 1:10, ""SCIE""), paste0(""PV"", 1:10, ""MATH""), paste0(""PV"", 1:10, ""READ""),"
"0","                   ""ESCS"", ""HISEI"", ""PAREDINT"", ""HOMEPOS"", ""WEALTH"", ""ICTRES"", ""HEDRES"")"
"0","    scie_vars <- intersect(names(stu_dt), scie_vars)"
"0","    mice_data <- as.data.frame(stu_dt[, scie_vars, with = FALSE])"
"0","    mice_methods <- make.method(mice_data)"
"0","    for (pv in 1:10) {"
"0","      scie_var <- paste0(""PV"", pv, ""SCIE"")"
"0","      if (scie_var %in% names(mice_data)) {"
"0","        mice_methods[scie_var] <- ""pmm"""
"0","      }"
"0","    }"
"0","    tryCatch({"
"0","      mice_result <- mice(mice_data, m = 5, method = mice_methods, printFlag = FALSE, seed = 42)"
"0","      completed_mice <- complete(mice_result, 1)"
"0","      for (pv in 1:10) {"
"0","        scie_var <- paste0(""PV"", pv, ""SCIE"")"
"0","        if (scie_var %in% names(completed_mice)) {"
"0","          stu_dt[, (scie_var) := completed_mice[[scie_var]]]"
"0","        }"
"0","      }"
"0","      cat(""âœ“ SCIE plausible values imputation completed\n"")"
"0","    }, error = function(e) {"
"0","      cat(sprintf(""ERROR in SCIE imputation for cycle %s: %s\n"", cycle_year, e$message))"
"0","    })"
"0","  } else if (scie_missing_pct > 30) {"
"0","    cat(""âš  SCIE missingness >30%, skipping imputation\n"")"
"0","  }"
"0","  "
"0","  # Impute READ plausible values if missingness is <= 30%"
"0","  read_missing_pct <- mean(rowSums(is.na(stu_dt[, .SD, .SDcols = patterns(""READ$"")])) > 0) * 100"
"0","  cat(sprintf(""READ plausible values missingness: %.1f%%\n"", read_missing_pct))"
"0","  if (read_missing_pct > 0 && read_missing_pct <= 30) {"
"0","    cat(""â†’ Imputing READ plausible values using MICE...\n"")"
"0","    read_vars <- c(paste0(""PV"", 1:10, ""READ""), paste0(""PV"", 1:10, ""MATH""), paste0(""PV"", 1:10, ""SCIE""),"
"0","                   ""ESCS"", ""HISEI"", ""PAREDINT"", ""HOMEPOS"", ""WEALTH"", ""ICTRES"", ""HEDRES"")"
"0","    read_vars <- intersect(names(stu_dt), read_vars)"
"0","    mice_data <- as.data.frame(stu_dt[, read_vars, with = FALSE])"
"0","    mice_methods <- make.method(mice_data)"
"0","    for (pv in 1:10) {"
"0","      read_var <- paste0(""PV"", pv, ""READ"")"
"0","      if (read_var %in% names(mice_data)) {"
"0","        mice_methods[read_var] <- ""pmm"""
"0","      }"
"0","    }"
"0","    tryCatch({"
"0","      mice_result <- mice(mice_data, m = 5, method = mice_methods, printFlag = FALSE, seed = 42)"
"0","      completed_mice <- complete(mice_result, 1)"
"0","      for (pv in 1:10) {"
"0","        read_var <- paste0(""PV"", pv, ""READ"")"
"0","        if (read_var %in% names(completed_mice)) {"
"0","          stu_dt[, (read_var) := completed_mice[[read_var]]]"
"0","        }"
"0","      }"
"0","      cat(""âœ“ READ plausible values imputation completed\n"")"
"0","    }, error = function(e) {"
"0","      cat(sprintf(""ERROR in READ imputation for cycle %s: %s\n"", cycle_year, e$message))"
"0","    })"
"0","  } else if (read_missing_pct > 30) {"
"0","    cat(""âš  READ missingness >30%, skipping imputation\n"")"
"0","  }"
"0","  "
"0","  # Calculate national ESCS threshold"
"0","  escs_q25_national <- quantile(stu_dt$ESCS, probs = 0.25, na.rm = TRUE)"
"0","  "
"0","  # Apply DISADVANTAGED definition"
"0","  stu_dt[, DISADVANTAGED := ifelse(ESCS <= escs_q25_national, 1, 0)]"
"0","  "
"0","  # Compute resilience indicators for each plausible value set"
"0","  orig_resilient_props <- numeric(10)"
"0","  oecd_resilient_props <- numeric(10)"
"0","  revised_resilient_props <- numeric(10)"
"0","  orig_resilient_vars <- numeric(10)"
"0","  oecd_resilient_vars <- numeric(10)"
"0","  revised_resilient_vars <- numeric(10)"
"0","  "
"0","  for (pv in 1:10) {"
"0","    # Extract plausible value for each domain"
"0","    stu_dt[, `:=`("
"0","      MATH_PV = get(paste0(""PV"", pv, ""MATH"")),"
"0","      READ_PV = get(paste0(""PV"", pv, ""READ"")),"
"0","      SCIE_PV = get(paste0(""PV"", pv, ""SCIE""))"
"0","    )]"
"0","    stu_dt[, ACHIEVEMENT_PV := (MATH_PV + READ_PV + SCIE_PV) / 3]"
"0","    "
"0","    # Calculate national thresholds for this plausible value"
"0","    math_q75_national <- quantile(stu_dt$MATH_PV, probs = 0.75, na.rm = TRUE)"
"0","    read_q75_national <- quantile(stu_dt$READ_PV, probs = 0.75, na.rm = TRUE)"
"0","    scie_q75_national <- quantile(stu_dt$SCIE_PV, probs = 0.75, na.rm = TRUE)"
"0","    achievement_q75_national <- quantile(stu_dt$ACHIEVEMENT_PV, probs = 0.75, na.rm = TRUE)"
"0","    "
"0","    # Original resilience (Level 3 thresholds)"
"0","    # Note: Level 2 thresholds (MATH: 420.07, READ: 407.47, SCIE: 409.54) can be used for sensitivity analysis"
"0","    MATH_LEVEL3_THRESHOLD <- 482.38"
"0","    READ_LEVEL3_THRESHOLD <- 480.18"
"0","    SCIE_LEVEL3_THRESHOLD <- 484.14"
"0","    stu_dt[DISADVANTAGED == 1, paste0(""RESILIENT_PV"", pv) := ifelse("
"0","      MATH_PV >= MATH_LEVEL3_THRESHOLD &"
"0","        READ_PV >= READ_LEVEL3_THRESHOLD &"
"0","        SCIE_PV >= SCIE_LEVEL3_THRESHOLD, 1, 0)]"
"0","    "
"0","    # OECD resilience (bottom 25% ESCS, top 25% overall achievement)"
"0","    stu_dt[DISADVANTAGED == 1, paste0(""RESILIENT_OECD_PV"", pv) := ifelse("
"0","      ESCS <= escs_q25_national & ACHIEVEMENT_PV >= achievement_q75_national, 1, 0)]"
"0","    "
"0","    # Revised resilience (bottom 25% ESCS, top 25% in each domain)"
"0","    stu_dt[DISADVANTAGED == 1, paste0(""RESILIENT_REVISED_PV"", pv) := ifelse("
"0","      ESCS <= escs_q25_national &"
"0","        MATH_PV >= math_q75_national &"
"0","        READ_PV >= read_q75_national &"
"0","        SCIE_PV >= scie_q75_national, 1, 0)]"
"0","    "
"0","    # Calculate achievement averages for clustering (add this back)"
"0","    stu_dt[, MATH_AVG := rowMeans(.SD, na.rm = TRUE), .SDcols = patterns(""^PV[0-9]+MATH$"")]"
"0","    stu_dt[, READ_AVG := rowMeans(.SD, na.rm = TRUE), .SDcols = patterns(""^PV[0-9]+READ$"")]  "
"0","    stu_dt[, SCIE_AVG := rowMeans(.SD, na.rm = TRUE), .SDcols = patterns(""^PV[0-9]+SCIE$"")]"
"0","    "
"0","    "
"0","    # Compute proportions for pooled summary statistics"
"0","    disadv_dt <- stu_dt[DISADVANTAGED == 1]"
"0","    n_disadv <- nrow(disadv_dt)"
"0","    if (n_disadv == 0) {"
"0","      cat(sprintf(""Error: No disadvantaged students in cycle %s after processing\n"", cycle_year))"
"0","      return(NULL)"
"0","    }"
"0","    orig_resilient_props[pv] <- mean(disadv_dt[[paste0(""RESILIENT_PV"", pv)]], na.rm = TRUE)"
"0","    oecd_resilient_props[pv] <- mean(disadv_dt[[paste0(""RESILIENT_OECD_PV"", pv)]], na.rm = TRUE)"
"0","    revised_resilient_props[pv] <- mean(disadv_dt[[paste0(""RESILIENT_REVISED_PV"", pv)]], na.rm = TRUE)"
"0","    orig_resilient_vars[pv] <- var(disadv_dt[[paste0(""RESILIENT_PV"", pv)]], na.rm = TRUE) / n_disadv"
"0","    oecd_resilient_vars[pv] <- var(disadv_dt[[paste0(""RESILIENT_OECD_PV"", pv)]], na.rm = TRUE) / n_disadv"
"0","    revised_resilient_vars[pv] <- var(disadv_dt[[paste0(""RESILIENT_REVISED_PV"", pv)]], na.rm = TRUE) / n_disadv"
"0","  }"
"0","  "
"0","  # Create final binary resilience indicators using majority rule"
"0","  orig_resilient_cols <- paste0(""RESILIENT_PV"", 1:10)"
"0","  oecd_resilient_cols <- paste0(""RESILIENT_OECD_PV"", 1:10)"
"0","  revised_resilient_cols <- paste0(""RESILIENT_REVISED_PV"", 1:10)"
"0","  stu_dt[, RESILIENT := ifelse(rowSums(.SD, na.rm = TRUE) >= 5, 1, 0), .SDcols = orig_resilient_cols]"
"0","  stu_dt[, RESILIENT_OECD := ifelse(rowSums(.SD, na.rm = TRUE) >= 5, 1, 0), .SDcols = oecd_resilient_cols]"
"0","  stu_dt[, RESILIENT_REVISED := ifelse(rowSums(.SD, na.rm = TRUE) >= 5, 1, 0), .SDcols = revised_resilient_cols]"
"0","  "
"0","  # Pool proportions using Rubin's rules for comparison"
"0","  pool_proportions <- function(props, vars, n) {"
"0","    mean_prop <- mean(props)"
"0","    within_var <- mean(vars)"
"0","    between_var <- var(props)"
"0","    total_var <- within_var + between_var * (1 + 1/length(props))"
"0","    se <- sqrt(total_var)"
"0","    return(list(mean = mean_prop, se = se, n = round(mean_prop * n)))"
"0","  }"
"0","  "
"0","  n_disadv <- nrow(stu_dt[DISADVANTAGED == 1])"
"0","  orig_pooled <- pool_proportions(orig_resilient_props, orig_resilient_vars, n_disadv)"
"0","  oecd_pooled <- pool_proportions(oecd_resilient_props, oecd_resilient_vars, n_disadv)"
"0","  revised_pooled <- pool_proportions(revised_resilient_props, revised_resilient_vars, n_disadv)"
"0","  "
"0","  # Compute correlations for SES variables"
"0","  ses_vars <- intersect(names(stu_dt), c(""ESCS"", ""HISEI"", ""HOMEPOS"", ""WEALTH""))"
"0","  if (length(ses_vars) >= 2) {"
"0","    cat(sprintf(""Correlations for SES variables in %s:\n"", cycle_year))"
"0","    print(cor(stu_dt[DISADVANTAGED == 1, .SD, .SDcols = ses_vars], use = ""pairwise.complete.obs""))"
"0","  }"
"0","  "
"0","  # Filter to disadvantaged students"
"0","  disadv_dt <- stu_dt[DISADVANTAGED == 1]"
"0","  "
"0","  # Merge with school data"
"0","  if (!is.null(sch_dt) && nrow(sch_dt) > 0) {"
"0","    tryCatch({"
"0","      disadv_dt <- merge(disadv_dt, sch_dt, by = c(""CNT"", ""CNTSCHID"", ""CYCLE""), all.x = TRUE)"
"0","      if (nrow(disadv_dt) == 0) {"
"0","        cat(sprintf(""Error: Merge resulted in empty dataset for cycle %s\n"", cycle_year))"
"0","        return(NULL)"
"0","      }"
"0","    }, error = function(e) {"
"0","      cat(sprintf(""ERROR in merge for cycle %s: %s\n"", cycle_year, e$message))"
"0","      return(NULL)"
"0","    })"
"0","  } else {"
"0","    cat(sprintf(""Warning: No school data for cycle %s, proceeding with student data only\n"", cycle_year))"
"0","  }"
"0","  "
"0","  # Clean up temporary columns"
"0","  disadv_dt[, grep(""PV[0-9]+"", names(disadv_dt)) := NULL]"
"0","  disadv_dt[, c(""MATH_PV"", ""READ_PV"", ""SCIE_PV"", ""ACHIEVEMENT_PV"") := NULL]"
"0","  "
"0","  return(list("
"0","    data = disadv_dt,"
"0","    pooled_results = list("
"0","      original = orig_pooled,"
"0","      oecd = oecd_pooled,"
"0","      revised = revised_pooled"
"0","    )"
"0","  ))"
"0","}"
"0",""
"0","# ---- Apply Processing ----"
"0","processed_list <- list()"
"0","for (cycle_name in names(pisa_cycles)) {"
"0","  result <- process_pisa_cycle(pisa_student_list[[cycle_name]], pisa_school_list[[cycle_name]], cycle_name)"
"0","  if (!is.null(result)) {"
"0","    processed_list[[cycle_name]] <- result"
"0","  } else {"
"0","    cat(sprintf(""Skipping cycle %s due to processing failure\n"", cycle_name))"
"0","  }"
"0","}"
"1","Error: No valid student data for cycle 2015
"
"1","Skipping cycle 2015 due to processing failure
"
"1","Error: No valid student data for cycle 2018
"
"1","Skipping cycle 2018 due to processing failure
"
"1","Error: No valid student data for cycle 2022
"
"1","Skipping cycle 2022 due to processing failure
"
"0","# ---- Data Processing Summary ----"
"0","cat(""\n=== DATA PROCESSING SUMMARY ===\n"")"
"1","
=== DATA PROCESSING SUMMARY ===
"
"0","for (cycle in names(processed_list)) {"
"0","  if (!is.null(processed_list[[cycle]])) {"
"0","    data <- processed_list[[cycle]]$data  # Individual student data"
"0","    n_students <- nrow(data)"
"0","    "
"0","    # Calculate from individual binary indicators (consistent with clustering)"
"0","    n_resilient_orig <- sum(data$RESILIENT, na.rm = TRUE)"
"0","    resilience_rate_orig <- round(mean(data$RESILIENT, na.rm = TRUE) * 100, 1)"
"0","    "
"0","    n_resilient_oecd <- sum(data$RESILIENT_OECD, na.rm = TRUE)"
"0","    resilience_rate_oecd <- round(mean(data$RESILIENT_OECD, na.rm = TRUE) * 100, 1)"
"0","    "
"0","    n_resilient_revised <- sum(data$RESILIENT_REVISED, na.rm = TRUE)"
"0","    resilience_rate_revised <- round(mean(data$RESILIENT_REVISED, na.rm = TRUE) * 100, 1)"
"0","    "
"0","    # Pooled estimates for comparison"
"0","    pooled <- processed_list[[cycle]]$pooled_results"
"0","    pooled_rate_orig <- round(pooled$original$mean * 100, 1)"
"0","    pooled_se_orig <- round(pooled$original$se * 100, 2)"
"0","    pooled_rate_oecd <- round(pooled$oecd$mean * 100, 1)"
"0","    pooled_se_oecd <- round(pooled$oecd$se * 100, 2)"
"0","    pooled_rate_revised <- round(pooled$revised$mean * 100, 1)"
"0","    pooled_se_revised <- round(pooled$revised$se * 100, 2)"
"0","    "
"0","    cat(sprintf(""- Cycle %s: %d disadvantaged students\n"", cycle, n_students))"
"0","    cat(sprintf(""  Original resilient (Level 3): %d (%.1f%%)\n"", n_resilient_orig, resilience_rate_orig))"
"0","    cat(sprintf(""  OECD resilient (relative): %d (%.1f%%)\n"", n_resilient_oecd, resilience_rate_oecd))"
"0","    cat(sprintf(""  Revised resilient (top 25%% each): %d (%.1f%%)\n"", n_resilient_revised, resilience_rate_revised))"
"0","    cat(sprintf(""  (Pooled estimates: Original %.1f%% Â± %.2f%%, OECD %.1f%% Â± %.2f%%, Revised %.1f%% Â± %.2f%%)\n"","
"0","                pooled_rate_orig, pooled_se_orig, pooled_rate_oecd, pooled_se_oecd, pooled_rate_revised, pooled_se_revised))"
"0","  }"
"0","}"
